# octo-whisper-conversation
## OllamaLanguage: Interactive Visualization of Language Model Responses

### Description
This repository presents a draft of an interactive visualization tool 
for exploring the responses generated by the Ollama Language Model (LLM). 
The primary objective is to deconstruct the model's responses into 
individual words and use them as data points for various visualizations. 
Additionally, this project aims to identify patterns in the model's 
output.

### Intent
To create an easy-to-understand tool that enables users to better 
understand the language models generated responses by deconstructing them and 
visualizing the results using 5p.js. The long-term goal is to identify patterns and 
trends within the model's output.

### Process and Tools
I start by installing Ollama locally and connecting to its API. 
Then, I modify the responses from a prompt by breaking them down into individual 
words, package them as JSON objects, and use those data points for visualization. 
Finally, I employ 5p.js to create various visualizations such as outline typo animation, 
word clouds and graphical grid animations.

### Prototypes
The current repository includes some prototypes that uses a prompt and view the 
generated responses in multiple visual formats. The 
initial focus is on deconstructing the response into individual words, but future 
iterations will explore identifying patterns and trends within the model's output.
- ollama_generativeTypo_basis: A first draft by just showing a question followed by the deconstructed answer randomly word by word
- ollama_generativeTypo_lineart: Question and deconstructed answer will be animated with outlines
- ollama_generativeTypo_cloud: Deconstructed anwsers are shown as vertical black clouds looking like lines
- ollama_generativeTypo_simpleGrid: Question and deconstructed answers shown in a simple grid
- ollame_generativeTypo_flickeringGrid: Question and deconstructed answers shown in a flickering grid with different options to try out by clicking 1, 2 or 3

### Conclusion and Outlook
Preliminary findings suggest that this tool could provide valuable insights 
into the language models response structure as well as to be helpful
in gaining a deeper understanding of how the model 
generates responses and identifying any biases or inconsistencies within its output. 
As I continue to develop this project, I anticipate further discoveries and 
improvements in the visualization methods and analysis techniques.

## Technical instructions
The idea is to run a local API on your machine. The LLM used hier is llama3.
For download checkout https://ollama.com (yes, the one with the so cute lama logo).

Some advantegs of llama next to being locally on your machine
- ollama pull llama3 → Load the brand new LLaMA-3 (also works)
- You can build your own models (model files)
- Supports system, user, assistant messages in chat style

The project for mainly all prottotypes mentioned above works as follows
1. A prompt given (hard coded and in my example "Why AI?") will be send to the local API.
2. The answer of the local LLM will be added word by word into an array.
3. The elements of the arry will be shown on screen one after another in random order.


### Pre-conditions
llama is installed on your local machine --> https://ollama.com

Next go to your porject folder an install node-fetch:
(`npm install node-fetch`) 

Workflow
### 1. Terminalfenster A – Modell starten
(`ollama run mistral`)

### 2. Terminalfenster B – Antwort holen
(`cd path/to/ollama_poetry
node index.js`) 
If needed pull model before with 
(`ollama pull llama3`)
(`ollama pull mistral`)

### 3. Terminalfenster C – Webserver starten
(`cd path/to/ollama_poetry
http-server`)

### 4. Browser → http://localhost:8080 öffnen
opene localhost in browser and the magic should beginn
